# Machine Learning Course Repository

Welcome to the Machine Learning Course Repository! This repository contains code and resources related to various topics in machine learning covered in the course. Below you will find a description of each topic, along with the relevant code and examples.

## Table of Contents

- [Introduction](#introduction)
- [Supervised Learning](#supervised-learning)
  - [Decision Trees](#decision-trees)
  - [Feature Engineering - Numerical Transformations](#feature-engineering---numerical-transformations)
  - [Feature Selection](#feature-selection)
  - [K-Nearest Neighbors (KNN)](#k-nearest-neighbors-knn)
  - [Linear Regression](#linear-regression)
  - [Logistic Regression](#logistic-regression)
  - [Evaluation Metrics for Classification](#evaluation-metrics-for-classification)
  - [Naive Bayes](#naive-bayes)
  - [Support Vector Machines (SVM)](#support-vector-machines-svm)
  - [Regularization and Hyperparameter Tuning](#regularization-and-hyperparameter-tuning)
  - [Random Forests](#random-forests)
  - [Boosting ML Models](#boosting-ml-models)
- [Unsupervised Learning](#unsupervised-learning)
  - [K-Means Clustering](#k-means-clustering)
  - [Principal Component Analysis (PCA)](#principal-component-analysis-pca)
- [Deep Learning](#Deep-Learning-TensorFlow)
- [Extra](#extra)
  - [PandasPractice](#pandaspractice)
  - [mlModelsScikitLearn](#mlmodelsscikitlearn)
  - [Classification Milestone Project 1 - End-to-End Heart Disease Classification](#classification-milestone-project-1---end-to-end-heart-disease-classification)


## Introduction

This repository contains a collection of machine learning algorithms, techniques, and examples. 

## Supervised Learning

Supervised learning involves learning a function that maps an input to an output based on example input-output pairs. It includes tasks such as classification and regression.

### Decision Trees

Decision Trees are used for classification and regression tasks. They work by splitting the data into subsets based on the value of input features.

- **Code**: See the `DecisionTrees` directory for implementation details.

### Feature Engineering - Numerical Transformations

Feature Engineering involves transforming raw data into meaningful features that better represent the underlying problem to predictive models.

- **Code**: See the `FeatureEngineering-NumericalTransformations` directory for implementation details.

### Feature Selection

Feature Selection is the process of selecting a subset of relevant features for use in model construction.

- **Code**: See the `FeatureSelection` directory for implementation details.

### K-Nearest Neighbors (KNN)

K-Nearest Neighbors is an instance-based learning algorithm used for classification and regression.

- **Code**: See the `K_nearestNeighbors` directory for implementation details.

### Linear Regression

Linear Regression is a linear approach to modeling the relationship between a dependent variable and one or more independent variables.

- **Code**: See the `LinearRegression` directory for implementation details.

### Logistic Regression

Logistic Regression is used for binary classification problems and models the probability that a given input point belongs to a certain class.

- **Code**: See the `LogisticRegression` directory for implementation details.

### Evaluation Metrics for Classification

Evaluation metrics for classification are quantitative measures used to assess the performance of a classification model. They provide insights into the accuracy, precision, recall, F1 score, and overall effectiveness of the model in correctly predicting class labels.

- **Code**: See the `EvaluationMetricsClassification` directory for implementation details.

### Naive Bayes

Naive Bayes classifiers are simple probabilistic classifiers based on Bayes' theorem with strong independence assumptions between the features.

- **Code**: See the `NaiveBayes` directory for implementation details.

### Support Vector Machines (SVM)

Support Vector Machines are supervised learning models used for classification and regression by finding the hyperplane that best divides a dataset into classes.

- **Code**: See the `SupportVectorMachine` directory for implementation details.

### Regularization and Hyperparameter Tuning

Regularization is used to prevent overfitting, while hyperparameter tuning involves optimizing the hyperparameters of a model to improve its performance.

- **Code**: See the `Regularization` directory for implementation details.

### Random Forests

Random Forests are an ensemble learning method that constructs multiple decision trees and merges them to get a more accurate and stable prediction.

- **Code**: See the `RandomForests` directory for implementation details.

### Boosting ML Models

Boosting is an ensemble technique that combines the predictions of several base estimators to improve robustness over a single estimator.

- **Code**: See the `Boosting` directory for implementation details.

## Unsupervised Learning

Unsupervised learning involves learning patterns from unlabeled data. It includes tasks such as clustering and dimensionality reduction.

### K-Means Clustering

K-Means Clustering is an unsupervised learning algorithm used to partition a dataset into K distinct, non-overlapping clusters.

- **Code**: See the `KmeansClustering` directory for implementation details.

### Principal Component Analysis (PCA)

Principal Component Analysis is a technique used to emphasize variation and bring out strong patterns in a dataset, reducing its dimensionality.

- **Code**: See the `Principal_component_analysis` directory for implementation details.

## Deep Learning

- **Code**: See the `Deep_Learning_TensorFlow` directory for implementation details.

## Extra

### PandasPractice

- **Code**: See the `PandasPractice` directory for examples and exercises on using pandas for data manipulation and analysis.

### mlModelsScikitLearn

- **Code**: See the `mlModelsScikitLearn` directory for various machine learning models implemented using scikit-learn.

### Classification Milestone Project 1 - End-to-End Heart Disease Classification

- **Code**: See the `ClassificationMilestoneProject1`
-  This project aims to build an end-to-end machine learning pipeline for heart disease classification. The goal is to predict the presence of heart disease in patients based on various medical attributes. The project covers all the essential steps from data preprocessing to model evaluation and deployment.
-  Uses Logistic Regression, KNN, Random Forest Classifier


## References
- Many explanations and concepts in this project are sourced from Codecademy's materials. Specific quotes and detailed explanations are by their courses.
- For more details, visit [Codecademy](https://www.codecademy.com/).
- Additional explanations are inspired by the [Complete Machine Learning and Data Science Zero to Mastery](https://www.udemy.com/course/complete-machine-learning-and-data-science-zero-to-mastery/?couponCode=ST19MT61724) course on Udemy.
